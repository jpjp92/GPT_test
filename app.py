# ### python -m streamlit run app.py

import gradio as gr
from g4f.client import Client

# GPT-4o-mini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = Client()

# ì±„íŒ… í•¨ìˆ˜ ì •ì˜
def chat_with_gpt(user_input, chat_history):
    try:
        # GPT-4o-mini ëª¨ë¸ì—ê²Œ ë©”ì‹œì§€ ì „ë‹¬ ë° ì‘ë‹µ ìƒì„±
        messages = [{"role": "system", "content": "You are a helpful assistant"}]
        for history in chat_history:
            messages.append({"role": "user", "content": history[0]})
            messages.append({"role": "assistant", "content": history[1]})
        messages.append({"role": "user", "content": user_input})

        # GPT ì‘ë‹µ ìƒì„±
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages
        )
        final_response = response.choices[0].message.content

        # ì±„íŒ… ê¸°ë¡ ì—…ë°ì´íŠ¸
        chat_history.append((user_input, final_response))
        return final_response, chat_history
    except Exception as e:
        return f"Error: {str(e)}", chat_history

# Gradio ì¸í„°í˜ì´ìŠ¤ ì •ì˜
with gr.Blocks() as demo:
    gr.Markdown("# GPT-4o-mini Chat ğŸ¤–")
    chatbot = gr.Chatbot()
    msg = gr.Textbox(label="GPTì—ê²Œ ì§ˆë¬¸í•˜ê¸°", placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")
    clear = gr.Button("ëŒ€í™” ì´ˆê¸°í™”")

    # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
    state = gr.State([])
    msg.submit(chat_with_gpt, [msg, state], [chatbot, state])
    clear.click(lambda: ([], []), None, [chatbot, state])

# ì•± ì‹¤í–‰
if __name__ == "__main__":
    demo.launch()





# import streamlit as st
# from g4f.client import Client

# # GPT-4o-mini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
# client = Client()

# # í˜ì´ì§€ ì„¤ì •: ì œëª©, ì•„ì´ì½˜, ë ˆì´ì•„ì›ƒ ì„¤ì •
# st.set_page_config(
#     page_title="GPT-4o Chat",
#     page_icon="ğŸ“",
#     layout="centered"
# )

# # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”: ì±„íŒ… ê¸°ë¡ ì €ì¥
# if "chat_history" not in st.session_state:
#     st.session_state.chat_history = []

# # ì•± ì œëª© í‘œì‹œ
# st.title("GPT-4o-mini Chat ğŸ¤–")

# # ì±„íŒ… ë©”ì‹œì§€ UI ì¶œë ¥
# for message in st.session_state.chat_history:
#     with st.chat_message(message['role']):
#         # ì‚¬ìš©ì ë˜ëŠ” GPTì˜ ë©”ì‹œì§€ë¥¼ êµ¬ë¶„í•´ ì¶œë ¥
#         st.markdown(message['content'])

# # ì‚¬ìš©ì ì…ë ¥ ì°½
# user_prompt = st.chat_input("GPT-4o-miniì—ê²Œ ì§ˆë¬¸í•´ë³´ì„¸ìš”!")

# if user_prompt:
#     # ì‚¬ìš©ìì˜ ì…ë ¥ ë©”ì‹œì§€ë¥¼ UIì— í‘œì‹œí•˜ê³  ì„¸ì…˜ ìƒíƒœì— ì €ì¥
#     st.chat_message("user").markdown(user_prompt)
#     st.session_state.chat_history.append({"role": "user", "content": user_prompt})

#     # GPT-4o-mini ëª¨ë¸ì—ê²Œ ë©”ì‹œì§€ ì „ë‹¬ ë° ì‘ë‹µ ìƒì„±
#     response = client.chat.completions.create(
#         model="gpt-4o-mini",
#         messages=[
#             {"role": "system", "content": "You are a helpful assistant"},  # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
#             *st.session_state.chat_history  # ì´ì „ ëŒ€í™” ë‚´ìš© í¬í•¨
#         ]
#     )
    
#     # GPT ì‘ë‹µ ê°€ì ¸ì˜¤ê¸°
#     final_response = response.choices[0].message.content

#     # GPT ì‘ë‹µì„ UIì— í‘œì‹œí•˜ê³  ì„¸ì…˜ ìƒíƒœì— ì €ì¥
#     st.session_state.chat_history.append({"role": "assistant", "content": final_response})
#     with st.chat_message("assistant"):
#         st.markdown(final_response)
